---
title: "Code to load cleaned cell-profile data and generate mapping inputs"
---

# Setup
```{r}
#| label: setup

library(data.table)
library(dplyr)
library(tidyr)
library(purrr)
library(stringr)
library(httr)
library(glue)

source("bin/outs.R")
```

# Overview 

The cleaned phenotype data is stored in the data cleaning [Github repo]('https://github.com/AndersenLab/2021_GWA_data_cleaning/tree/main/data/processed'). From the cleaned data, we generate mapping inputs for NemaScan. 

This script will pull the trait files from the data cleaning repo for the toxicants analyzed in this study, and format them for NemaScan.

The input format is a file where the rownames represent strain names, and the columns represent the traits to be mapped. The first column is the strain names, and the subsequent columns are the trait values.


# Inputs
```{r}
#| label: inputs

# Path to toxicant metadata file (generated by organize_tox_metadata.qmd)
con_metadata_fn <- "data/processed/tox_data/con_metadata.csv"

# GitHub repo details for downloading trait files
github_repo <- "AndersenLab/2021_GWA_data_cleaning"
github_branch <- "main"
github_traitfiles_path <- "data/processed/traitfiles"

# Expected date prefix in trait file names
date_prefix <- "20230322"

# Output path for generated trait file
output_fn <- "data/processed/aggregated_toxicant_traits.tsv"
```

# Load cleaned data

Download the cleaned data stored in the `traitfiles` folder of the data cleaning repo. The trait files are named according to the following convention: `<date>_<trait_name>_traitfile.tsv`, (e.g., `20230322_2_4_D_traitfile.tsv`, or `20230322_Aldicarb_traitfile.tsv`). Each file has three columns: `strain`, `<trait>_length`, `<trait_CV_length>`. 

The folder also contains other data collected for other chemicals not included here. So we filter to just the files that have the toxicant data.

```{r}
#| label: load-toxicant-metadata

# Load condition metadata to identify which toxicants to download
con_metadata <- data.table::fread(con_metadata_fn)

# Extract unique trait names, removing the "length_" prefix to get file name component
trait_info <- con_metadata %>%
  dplyr::select(trait, toxicant) %>%
  dplyr::distinct() %>%
  dplyr::mutate(
    # Remove "length_" prefix to get the trait name used in filenames
    trait_filename = stringr::str_replace(trait, "^length_", ""),
    # Fix decimal point issues: convert underscore before decimal numbers back to period
    # e.g., "Paraquat_62_5" -> "Paraquat_62.5"
    # This handles cases like: Paraquat_62.5, Silver_nitrate_7.8, Triphenyl_phosphate_6.25
    trait_filename = stringr::str_replace(trait_filename, "_(\\d+)_(\\d+)$", "_\\1.\\2"),
    # Construct expected filename
    filename = glue::glue("{date_prefix}_{trait_filename}_traitfile.tsv")
  )

print(glue::glue("Found {nrow(trait_info)} toxicant traits to download"))
print(trait_info)
```

```{r}
#| label: download-trait-files

# Function to download a single trait file from GitHub
download_trait_file <- function(filename, repo = github_repo, branch = github_branch,
                                path = github_traitfiles_path) {
  # Construct raw GitHub URL
  raw_url <- glue::glue("https://raw.githubusercontent.com/{repo}/{branch}/{path}/{filename}")

  message(glue::glue("Downloading: {filename}"))

  # Download file - httr handles authentication via .Renviron or system credentials
  response <- httr::GET(raw_url)

  # Check if download was successful
  if (httr::status_code(response) == 200) {
    # Parse content as text and read as data.table
    content_text <- httr::content(response, "text", encoding = "UTF-8")
    df <- data.table::fread(text = content_text)

    message(glue::glue("  ✓ Successfully downloaded {filename} ({nrow(df)} strains)"))
    return(df)
  } else {
    warning(glue::glue("  ✗ Failed to download {filename}: HTTP {httr::status_code(response)}"))
    return(NULL)
  }
}

# Download all trait files
trait_files_list <- purrr::map(trait_info$filename, download_trait_file)

# Name the list elements with the trait names for easy reference
names(trait_files_list) <- trait_info$trait

# Remove any NULL entries (failed downloads)
trait_files_list <- purrr::compact(trait_files_list)

print(glue::glue("Successfully downloaded {length(trait_files_list)} out of {nrow(trait_info)} trait files"))
```

# Aggregate trait data

Extract only the `<trait>_length` columns from each file and combine into a single wide-format dataframe where strains are rows and traits are columns.

```{r}
#| label: process-and-aggregate

# Function to extract and rename the length column from a trait file
process_trait_file <- function(df, trait_name) {
  # Identify the length column (should match pattern: <something>_length but not CV_length)
  length_col <- names(df)[stringr::str_detect(names(df), "_length$") &
    !stringr::str_detect(names(df), "^CV_")]

  if (length(length_col) == 0) {
    warning(glue::glue("No length column found for trait: {trait_name}"))
    return(NULL)
  }

  if (length(length_col) > 1) {
    warning(glue::glue("Multiple length columns found for trait: {trait_name}, using first"))
    length_col <- length_col[1]
  }

  # Select strain and length column, rename length column to match trait name
  # Note: trait_name should already have the "length_" prefix and underscores instead of periods
  result <- df %>%
    dplyr::select(strain, !!sym(length_col)) %>%
    dplyr::rename(!!trait_name := !!sym(length_col))

  return(result)
}

# Process each trait file
processed_traits <- purrr::imap(trait_files_list, ~ process_trait_file(.x, .y))

# Remove any NULL entries
processed_traits <- purrr::compact(processed_traits)

# Merge all trait dataframes by strain
# Start with the first dataframe
aggregated_traits <- processed_traits[[1]]

# Iteratively left join the remaining dataframes
if (length(processed_traits) > 1) {
  for (i in 2:length(processed_traits)) {
    aggregated_traits <- aggregated_traits %>%
      dplyr::full_join(processed_traits[[i]], by = "strain")
  }
}

print(glue::glue("Aggregated traits data:"))
print(glue::glue("  Strains: {nrow(aggregated_traits)}"))
print(glue::glue("  Traits: {ncol(aggregated_traits) - 1}"))
print(glue::glue("  Columns: {paste(names(aggregated_traits), collapse = ', ')}"))
```

```{r}
#| label: save-aggregated-data

# Save the aggregated trait file
save_tsv(
  data = aggregated_traits,
  output_file = output_fn
)

print(glue::glue("Saved aggregated traits to: {output_fn}"))
```

# Generate pheno.df.rda file

The `pheno.df.rda` file contains the full phenotype data for all wells and is used in various downstream analyses. This section downloads the cleaned data from the data cleaning GitHub repository and filters it to include only toxicant conditions (excluding controls).

## Download cleaned .Rdata file

```{r}
#| label: download-rdata-file

# Define paths
rdata_url <- glue::glue("https://raw.githubusercontent.com/{github_repo}/{github_branch}/data/processed/{date_prefix}_FINAL_cleaned_GWA.Rdata")
rdata_local_path <- glue::glue("data/raw/{date_prefix}_FINAL_cleaned_GWA.Rdata")
pheno_df_output <- "data/processed/phenotypes/pheno.df.rda"

# Download .Rdata file if it doesn't exist locally
if (!file.exists(rdata_local_path)) {
  message(glue::glue("Downloading {date_prefix}_FINAL_cleaned_GWA.Rdata from GitHub..."))

  response <- httr::GET(rdata_url)

  if (httr::status_code(response) == 200) {
    # Write binary content to file
    writeBin(httr::content(response, "raw"), rdata_local_path)
    message(glue::glue("  ✓ Successfully downloaded to {rdata_local_path}"))
  } else {
    stop(glue::glue("  ✗ Failed to download .Rdata file: HTTP {httr::status_code(response)}"))
  }
} else {
  message(glue::glue("Using existing file: {rdata_local_path}"))
}
```

## Process phenotype data

```{r}
#| label: process-pheno-data

# Load the .Rdata file
message("Loading cleaned GWA data...")
load(rdata_local_path)

# Check that the expected object exists
if (!exists("final.QC.GWA.df")) {
  stop("Expected object 'final.QC.GWA.df' not found in .Rdata file")
}

message(glue::glue("Loaded data with {nrow(final.QC.GWA.df)} rows"))

# Get list of toxicants from metadata (exclude controls)
# The new con_metadata only contains toxicants, so we can use it directly
tox_list <- con_metadata %>%
  dplyr::filter(type == "Toxicant") %>%
  dplyr::pull(drug) %>%
  unique()

message(glue::glue("Filtering to {length(tox_list)} toxicants"))

# Process the phenotype data
# Join with toxicant metadata and filter to only include toxicants
pheno.df <- final.QC.GWA.df %>%
  dplyr::filter(drug %in% tox_list) %>%
  dplyr::mutate(
    # Create well.id from Assay_Bleach, Metadata_Plate, and Metadata_Well
    well.id = paste(Assay_Bleach, Metadata_Plate, Metadata_Well, sep = "_"),
    # Replace PD1074 strain name with N2
    strain = ifelse(strain == "PD1074", "N2", strain)
  )

message(glue::glue("Processed phenotype data:"))
message(glue::glue("  Rows: {nrow(pheno.df)}"))
message(glue::glue("  Strains: {length(unique(pheno.df$strain))}"))
message(glue::glue("  Drugs: {length(unique(pheno.df$drug))}"))
message(glue::glue("  Columns: {ncol(pheno.df)}"))
```

## Save pheno.df.rda

```{r}
#| label: save-pheno-df

# Create output directory if it doesn't exist
output_dir <- dirname(pheno_df_output)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
  message(glue::glue("Created directory: {output_dir}"))
}

# Save the pheno.df object
save(pheno.df, file = pheno_df_output)

message(glue::glue("Saved pheno.df to: {pheno_df_output}"))
```

## Compare with existing file

```{r}
#| label: compare-versions

# Load the old version for comparison
old_pheno_path <- "data/raw/phenotypes/pheno.df.rda"

if (file.exists(old_pheno_path)) {
  message("\nComparing new version with existing file...")

  # Load old version
  load(old_pheno_path)
  old_pheno.df <- pheno.df

  # Load new version
  load(pheno_df_output)
  new_pheno.df <- pheno.df

  # Compare dimensions
  message(glue::glue("Old version: {nrow(old_pheno.df)} rows × {ncol(old_pheno.df)} columns"))
  message(glue::glue("New version: {nrow(new_pheno.df)} rows × {ncol(new_pheno.df)} columns"))

  # Compare columns
  old_cols <- colnames(old_pheno.df)
  new_cols <- colnames(new_pheno.df)

  missing_cols <- setdiff(old_cols, new_cols)
  extra_cols <- setdiff(new_cols, old_cols)

  if (length(missing_cols) > 0) {
    message(glue::glue("\nColumns in old but not in new: {paste(missing_cols, collapse=', ')}"))
  }

  if (length(extra_cols) > 0) {
    message(glue::glue("\nColumns in new but not in old: {paste(extra_cols, collapse=', ')}"))
  }

  if (length(missing_cols) == 0 && length(extra_cols) == 0) {
    message("\n✓ Column names match perfectly!")
  }

  # Compare unique drugs
  old_drugs <- sort(unique(old_pheno.df$drug))
  new_drugs <- sort(unique(new_pheno.df$drug))

  missing_drugs <- setdiff(old_drugs, new_drugs)
  extra_drugs <- setdiff(new_drugs, old_drugs)

  if (length(missing_drugs) > 0) {
    message(glue::glue("\nDrugs in old but not in new: {paste(missing_drugs, collapse=', ')}"))
  }

  if (length(extra_drugs) > 0) {
    message(glue::glue("\nDrugs in new but not in old: {paste(extra_drugs, collapse=', ')}"))
  }

  if (length(missing_drugs) == 0 && length(extra_drugs) == 0) {
    message("\n✓ Drug lists match perfectly!")
  }

  # Compare unique strains
  message(glue::glue("\nOld version strains: {length(unique(old_pheno.df$strain))}"))
  message(glue::glue("New version strains: {length(unique(new_pheno.df$strain))}"))
} else {
  message(glue::glue("\nOld version not found at {old_pheno_path}, skipping comparison"))
}
```

